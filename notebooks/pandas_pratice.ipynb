{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.Series( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_dataset = [1,2,3]\n",
    "basic_mix_dataset = [\"A\",\"B\",\"C\",1,2,3,{\"A1\",\"B1\",\"C1\"}]\n",
    "basic_multicol_dataset = {\"name\": [\"Allan\", \"Beatriz\", \"Clara\"], \"age\": [22,21,24]}\n",
    "basic_dict = {\"day_1\": 344, \"day_2\": 423, \"day_3\": 314}\n",
    "\n",
    "# pandas.Series(data, index, dtype, name, copy)\n",
    "    # one-dimensional (column), holding any data type\n",
    "        # if label isn't specified, values are labed with their index\n",
    "            # using labels you could access an item referring them, for create use: pd.Series(data, index = [x,y,z])\n",
    "my_series = pd.Series(basic_dict)\n",
    "first_day = my_series[\"day_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.DataFrame( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_dataset = [1,2,3]\n",
    "basic_mix_dataset = [\"A\",\"B\",\"C\",1,2,3,{\"A1\",\"B1\",\"C1\"}]\n",
    "basic_multicol_dataset = {\"name\": [\"Allan\", \"Beatriz\", \"Clara\"], \"age\": [22,21,24]}\n",
    "basic_dict = {\"day_1\": 344, \"day_2\": 423, \"day_3\": 314}\n",
    "\n",
    "\n",
    "# pandas.DataFrame(data, index, columns, dtype, copy)\n",
    "    # two-dimensional (rows, columns) \n",
    "my_dataframe = pd.DataFrame(basic_multicol_dataset)\n",
    "    \n",
    "    # for access one-more specified row, use: .loc\n",
    "my_dataframe.loc[1]     # one row, returns pd.Series(column) \n",
    "my_dataframe.loc[[0,2]] # multi rows, returns pd.DataFrame (rows, columns), for this you need to put [ [] ]\n",
    "    \n",
    "    # using \"index\", you can name the rows\n",
    "my_dataframe = pd.DataFrame(basic_multicol_dataset, index=[\"Firts\", \"Second\", \"Third\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.read_csv( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for load data set stored as csv, use:\n",
    "    # it will load as DataFrame\n",
    "load_csv = pd.read_csv(\"data/data.csv\") # specify file path\n",
    "\n",
    "    # use \".to_string()\" for print the entire DataFrame, with many rows it only will return first and last 5 rows\n",
    "        # to check how many rows the system's display, use: \"pd.options.display.max_rows\" = [60]\n",
    "print(load_csv.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.read_json( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for load data set stored as json, use:\n",
    "    # JSON is plain text, but has the format of an object\n",
    "load_json = pd.read_json(\"data/data.json\")\n",
    "\n",
    "    # for print the entire, uses \".to_string()\"\n",
    "print(load_json.to_string())\n",
    "\n",
    "    # JSON have the same structure as Python Dicts, for this, you can load a Python dict directly as .DataFrame()\n",
    "python_dict = {\n",
    "  \"Duration\":{\n",
    "    \"0\":60,\n",
    "    \"1\":60,\n",
    "    \"2\":60,\n",
    "    \"3\":45,\n",
    "    \"4\":45,\n",
    "    \"5\":60\n",
    "  },\n",
    "  \"Pulse\":{\n",
    "    \"0\":110,\n",
    "    \"1\":117,\n",
    "    \"2\":103,\n",
    "    \"3\":109,\n",
    "    \"4\":117,\n",
    "    \"5\":102\n",
    "  }\n",
    "}\n",
    " \n",
    "loading_pythondict_directly = pd.DataFrame(python_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for get a quicky overview of DataFrame, uses .head():\n",
    "    # this method returns the headers and the specified number of rows, if you dont specify, returns the top 5 rows\n",
    "load_json.head(5)\n",
    "\n",
    "    # for vizualize the last N rows, use .tail()\n",
    "load_json.tail(5)\n",
    "\n",
    "    # for see more information about the data set, uses: .info()\n",
    "        # tells how many rows and columns have, with the data type, tells how many Null values are present\n",
    "load_json.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Empty Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_dataset = pd.read_csv(\"data/bad_data.csv\")\n",
    "\n",
    "# for remove empty cells, use: .dropna( )\n",
    "    # by default, this method returns a new DataFrame, not change the original\n",
    "        # for change the original, uses the argument: \"inplace = True\"\n",
    "bad_dataset.info() # before .dropna()\n",
    "\n",
    "bad_dataset.dropna(inplace=True)\n",
    "\n",
    "bad_dataset.info() # after .dropna()\n",
    "\n",
    "# for replace NULL values with a specific one, uses .fillna()\n",
    "bad_dataset.fillna(130, inplace=True)\n",
    "\n",
    "# replace with MEAN MEDIAN and MODE\n",
    "mean = bad_dataset[\"Calories\"].mean()\n",
    "median = bad_dataset[\"Calories\"].median()\n",
    "mode = bad_dataset[\"Calories\"].mode\n",
    "    # after this, just uses .fillna(mean, inplace = )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Wrong Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the column \"Date\" has two cells with wrong format [\"NaN\", \"20201226\"]\n",
    "    # for fix his, pandas has: to_datetime(), if have problemas, uses format = \"mixed\" as arg\n",
    "bad_dataset = pd.read_csv('data/bad_data.csv')\n",
    "\n",
    "bad_dataset[\"Date\"] = pd.to_datetime(bad_dataset['Date'], format = \"mixed\")\n",
    "\n",
    "print(bad_dataset.to_string())\n",
    "\n",
    "# the NULL value still there, for remove empty cells from a specific column, uses: .dropna(subset[\"COLUMN\"])\n",
    "bad_dataset.dropna(subset=[\"Date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Wrong Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in row 7, the duration is 450, but for all the other rows the duration is between 30 and 60\n",
    "\n",
    "dataframe = pd.read_csv(\"data/bad_data.csv\")\n",
    "\n",
    "# .loc [{position}, \"{Column}\"] = {value}\n",
    "dataframe.loc[7, \"Duration\"] = 45 \n",
    "\n",
    "# for big data sets, you can use a loop\n",
    "for x in dataframe.index:\n",
    "    if dataframe.loc[x, \"Duration\"] > 120:\n",
    "        dataframe.drop(x, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplacates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_data = pd.read_csv(\"data/bad_data.csv\")\n",
    "\n",
    "# returns a Bool values for each row:\n",
    "print(duplicate_data.duplicated())\n",
    "\n",
    "# for remove uses:\n",
    "duplicate_data.drop_duplicates(inplace=True)\n",
    "\n",
    "print(duplicate_data.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/data.csv\")\n",
    "\n",
    "# corr() method calculates the relationship between each column in your data set, this method ignores \"not numeric\"\n",
    "df.corr()\n",
    "\n",
    "# 1 means that there is a 1 to 1 relationship (a perfect correlation)\n",
    "\n",
    "# 0.9 is also a good relationship, and if you increase one value, the other will probably increase as well.\n",
    "\n",
    "# -0.9 would be just as good relationship as 0.9, but if you increase one value, the other will probably go down.\n",
    "\n",
    "# 0.2 means NOT a good relationship, meaning that if one value goes up does not mean that the other will."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing library to visualize the diagram\n",
    "import matplotlib.pyplot as plt\n",
    "    # standard visualization\n",
    "df = pd.read_csv(\"data/data.csv\")\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "    # using arg .plot( kind= \"scatter\" ) \n",
    "        # and include x & y axis\n",
    "df.plot( kind= \"scatter\", x=\"Duration\", y=\"Calories\")\n",
    "\n",
    "# we learned that the correlation between \"Duration\" and \"Calories\"\n",
    "    # looking at the scatterplot, we will agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram\n",
    "    # histogram just need one column\n",
    "        # for this you need to plot directly on the df column\n",
    "df[\"Duration\"].plot(kind=\"hist\", xlabel= \"Duration\")\n",
    "\n",
    "# this graph tells that there were over 100 workouts that lasted between 50 and 60 minutes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
